from sklearn.model_selection import train_test_split
import numpy as np

# Example data with balanced classes
X = np.random.rand(100, 5)  # 100 samples, 5 features
y = np.random.randint(0, 2, 100)  # Binary labels

# Verify class distribution
print("Original class counts:", np.unique(y, return_counts=True))

# Initial split (stratified)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Check if stratification is possible for validation/test
if min(np.unique(y_temp, return_counts=True)[1]) >= 2:
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
else:
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42
    )

print("Train/Val/Test sizes:", len(X_train), len(X_val), len(X_test))


output:
Original class counts: (array([0, 1]), array([49, 51]))
Train/Val/Test sizes: 70 15 15

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, None]
}

grid = GridSearchCV(RandomForestRegressor(), params, cv=5, scoring='neg_mean_squared_error')
grid.fit(X_val, y_val)
print("Best params:", grid.best_params_)


output:
Best params: {'max_depth': 10, 'n_estimators': 100}







